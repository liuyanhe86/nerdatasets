{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c17c7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir, dev_dir, test_dir = './supervised/supervised/train.txt', './supervised/supervised/dev.txt', './supervised/supervised/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67af3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131767\n",
      "18824\n",
      "37648\n",
      "188239\n"
     ]
    }
   ],
   "source": [
    "train_sentences = []\n",
    "raw_lines = []\n",
    "with open(train_dir, encoding='utf-8') as f:\n",
    "    raw_lines = f.readlines()\n",
    "raw_lines[-1] = raw_lines[-1] + '\\n'\n",
    "raw_lines.extend(['\\n'])\n",
    "raw_lines = [line.strip() for line in raw_lines]\n",
    "\n",
    "beg, end = 0, 0\n",
    "while end < len(raw_lines):\n",
    "    if raw_lines[end]:\n",
    "        end += 1\n",
    "    else:\n",
    "        sentence = raw_lines[beg:end]\n",
    "        train_sentences.append(sentence)\n",
    "        end += 1\n",
    "        beg = end\n",
    "print(len(train_sentences))\n",
    "\n",
    "valid_sentences = []\n",
    "raw_lines = []\n",
    "with open(dev_dir, encoding='utf-8') as f:\n",
    "    raw_lines = f.readlines()\n",
    "raw_lines[-1] = raw_lines[-1] + '\\n'\n",
    "raw_lines.extend(['\\n'])\n",
    "raw_lines = [line.strip() for line in raw_lines]\n",
    "\n",
    "beg, end = 0, 0\n",
    "while end < len(raw_lines):\n",
    "    if raw_lines[end]:\n",
    "        end += 1\n",
    "    else:\n",
    "        sentence = raw_lines[beg:end]\n",
    "        valid_sentences.append(sentence)\n",
    "        end += 1\n",
    "        beg = end\n",
    "print(len(valid_sentences))\n",
    "\n",
    "test_sentences = []\n",
    "with open(test_dir, encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "lines[-1] = lines[-1] + '\\n'\n",
    "lines.extend(['\\n'])\n",
    "lines = [line.strip() for line in lines]\n",
    "beg, end = 0, 0\n",
    "while end < len(lines):\n",
    "    if lines[end]:\n",
    "        end += 1\n",
    "    else:\n",
    "        sentence = lines[beg:end]\n",
    "        test_sentences.append(sentence)\n",
    "        end += 1\n",
    "        beg = end\n",
    "print(len(test_sentences))\n",
    "print(len(train_sentences) + len(valid_sentences) + len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed136d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114028\n",
      "16343\n",
      "32565\n",
      "162936\n"
     ]
    }
   ],
   "source": [
    "washed_train_sentences = []\n",
    "for sentence in train_sentences:\n",
    "    for i in range(len(sentence)):\n",
    "        word_tag = sentence[i]\n",
    "        tokens = word_tag.split('\\t')\n",
    "        if tokens[1] != 'O':\n",
    "            if '/' in tokens[1]:\n",
    "                tokens[1] = tokens[1].replace('/', ',')\n",
    "                sentence[i] = '\\t'.join(tokens)\n",
    "    O_count = sum([1 if wt.endswith('\\tO') else 0 for wt in sentence])\n",
    "    if O_count != 0 and O_count != len(sentence):\n",
    "        washed_train_sentences.append(sentence)\n",
    "print(len(washed_train_sentences))\n",
    "\n",
    "washed_valid_sentences = []\n",
    "for sentence in valid_sentences:\n",
    "    for i in range(len(sentence)):\n",
    "        word_tag = sentence[i]\n",
    "        tokens = word_tag.split('\\t')\n",
    "        if tokens[1] != 'O':\n",
    "            if '/' in tokens[1]:\n",
    "                tokens[1] = tokens[1].replace('/', ',')\n",
    "                sentence[i] = '\\t'.join(tokens)\n",
    "    O_count = sum([1 if wt.endswith('\\tO') else 0 for wt in sentence])\n",
    "    if O_count != 0 and O_count != len(sentence):\n",
    "        washed_valid_sentences.append(sentence)\n",
    "print(len(washed_valid_sentences))\n",
    "\n",
    "washed_test_sentences = []\n",
    "for sentence in test_sentences:\n",
    "    for i in range(len(sentence)):\n",
    "        word_tag = sentence[i]\n",
    "        tokens = word_tag.split('\\t')\n",
    "        if tokens[1] != 'O':\n",
    "            if '/' in tokens[1]:\n",
    "                tokens[1] = tokens[1].replace('/', ',')\n",
    "                sentence[i] = '\\t'.join(tokens)\n",
    "    O_count = sum([1 if wt.endswith('\\tO') else 0 for wt in sentence])\n",
    "    if O_count != 0 and O_count != len(sentence):\n",
    "        washed_test_sentences.append(sentence)\n",
    "print(len(washed_test_sentences))\n",
    "print(len(washed_train_sentences) + len(washed_valid_sentences) + len(washed_test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba08f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154387\n",
      "coarse classes: {'organization', 'building', 'art', 'person', 'product', 'other', 'event', 'location'}\n"
     ]
    }
   ],
   "source": [
    "all_sentences = list(set(['\\n'.join(s) for s in washed_train_sentences] + ['\\n'.join(s) for s in washed_valid_sentences] + ['\\n'.join(s) for s in washed_test_sentences]))\n",
    "print(len(all_sentences))\n",
    "coarse_classes = set()\n",
    "for i in range(len(all_sentences)):\n",
    "    wts = all_sentences[i].split('\\n')\n",
    "    for j in range(len(wts)):\n",
    "        tokens = wts[j].split('\\t')\n",
    "        if tokens[1] != 'O':\n",
    "            coarse_tag = tokens[1].split('-')[0]\n",
    "            wts[j] = tokens[0] + '\\t' + coarse_tag\n",
    "            coarse_classes.add(coarse_tag)\n",
    "    all_sentences[i] = '\\n'.join(wts)\n",
    "print(f'coarse classes: {coarse_classes}')\n",
    "coarse_dict = {}\n",
    "\n",
    "for coarse_class in coarse_classes:\n",
    "    sentences = []\n",
    "    for sentence in all_sentences:\n",
    "        wts = sentence.split('\\n')\n",
    "        for word_tag in wts:\n",
    "            tag = word_tag.split('\\t')[1]\n",
    "            if tag == coarse_class:\n",
    "                sentences.append(sentence)\n",
    "                break\n",
    "    coarse_dict[coarse_class] = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d54e3eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261832\n",
      "{'organization': 55286, 'building': 17189, 'art': 12676, 'person': 55494, 'product': 16208, 'other': 23585, 'event': 15074, 'location': 66320}\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "tag_count = {}\n",
    "for cc in coarse_classes:\n",
    "    tag_count[cc] = len(coarse_dict[cc])\n",
    "    count += len(coarse_dict[cc])\n",
    "print(count)\n",
    "print(tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "320b0e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108105\n",
      "{'organization': 38701, 'product': 11346, 'location': 46424, 'other': 16510, 'event': 10552, 'person': 38846, 'building': 12033, 'art': 8874}\n",
      "{'organization': 55286, 'building': 17189, 'art': 12676, 'person': 55494, 'product': 16208, 'other': 23585, 'event': 15074, 'location': 66320}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_samples = set()\n",
    "train_samples_count = {}\n",
    "for tag in coarse_classes:\n",
    "    samples = coarse_dict[tag]\n",
    "    while train_samples_count.get(tag, 0) < 0.7 * tag_count[tag]:\n",
    "        sample = random.choice(samples)\n",
    "        if sample not in train_samples:\n",
    "            satisfied = True\n",
    "            other_tags = set([wt.split('\\t')[1] for wt in sample.split('\\n')])\n",
    "            for other_tag in other_tags:\n",
    "                if other_tag != 'O' and other_tag != tag:\n",
    "                    if train_samples_count.get(other_tag, 0) + 1 > 0.7 * tag_count[other_tag]:\n",
    "                        satisfied = False\n",
    "                        break\n",
    "            if satisfied:\n",
    "                train_samples.add(sample)\n",
    "                train_samples_count[tag] = train_samples_count.get(tag, 0) + 1\n",
    "                for other_tag in other_tags:\n",
    "                    if other_tag != 'O' and other_tag != tag:\n",
    "                        train_samples_count[other_tag] = train_samples_count.get(other_tag, 0) + 1\n",
    "print(len(train_samples))\n",
    "print(train_samples_count)\n",
    "print(tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aedf6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organization : 0.7000144702094563\n",
      "product : 0.7000246791707798\n",
      "location : 0.7\n",
      "other : 0.7000211999152003\n",
      "event : 0.7000132678784662\n",
      "person : 0.7000036039932245\n",
      "building : 0.7000407237186573\n",
      "art : 0.7000631113916062\n"
     ]
    }
   ],
   "source": [
    "for tag in train_samples_count:\n",
    "    print(tag, ':', train_samples_count[tag] / tag_count[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afafa187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15421\n",
      "{'organization': 5529, 'location': 6632, 'event': 1508, 'person': 5550, 'product': 1621, 'other': 2359, 'art': 1268, 'building': 1719}\n",
      "{'organization': 55286, 'building': 17189, 'art': 12676, 'person': 55494, 'product': 16208, 'other': 23585, 'event': 15074, 'location': 66320}\n"
     ]
    }
   ],
   "source": [
    "valid_samples = set()\n",
    "valid_samples_count = {}\n",
    "for tag in coarse_classes:\n",
    "    samples = coarse_dict[tag]\n",
    "    while valid_samples_count.get(tag, 0) < 0.1 * tag_count[tag]:\n",
    "        sample = random.choice(samples)\n",
    "        if sample not in train_samples and sample not in valid_samples:\n",
    "            satisfied = True\n",
    "            other_tags = set([wt.split('\\t')[1] for wt in sample.split('\\n')])\n",
    "            for other_tag in other_tags:\n",
    "                if other_tag != 'O' and other_tag != tag:\n",
    "                    if valid_samples_count.get(other_tag, 0) + 1 > 0.1 * tag_count[other_tag]:\n",
    "                        satisfied = False\n",
    "                        break\n",
    "            if satisfied:\n",
    "                valid_samples.add(sample)\n",
    "                valid_samples_count[tag] = valid_samples_count.get(tag, 0) + 1\n",
    "                for other_tag in other_tags:\n",
    "                    if other_tag != 'O' and other_tag != tag:\n",
    "                        valid_samples_count[other_tag] = valid_samples_count.get(other_tag, 0) + 1\n",
    "print(len(valid_samples))\n",
    "print(valid_samples_count)\n",
    "print(tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3f31488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organization : 0.10000723510472814\n",
      "location : 0.1\n",
      "event : 0.1000398036353987\n",
      "person : 0.10001081197967347\n",
      "product : 0.10001233958538994\n",
      "other : 0.10002119991520034\n",
      "art : 0.10003155569580309\n",
      "building : 0.1000058176740939\n"
     ]
    }
   ],
   "source": [
    "for tag in valid_samples_count:\n",
    "    print(tag, ':', valid_samples_count[tag] / tag_count[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11cbadef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30324\n",
      "{'organization': 10878, 'building': 3397, 'art': 2455, 'person': 10772, 'product': 3203, 'other': 4691, 'event': 2980, 'location': 13039}\n",
      "{'organization': 55286, 'building': 17189, 'art': 12676, 'person': 55494, 'product': 16208, 'other': 23585, 'event': 15074, 'location': 66320}\n"
     ]
    }
   ],
   "source": [
    "test_samples = set()\n",
    "test_samples_count = {}\n",
    "\n",
    "for tag in coarse_classes:\n",
    "    samples = set(coarse_dict[tag]).difference(train_samples.union(valid_samples))\n",
    "    test_samples_count[tag] = test_samples_count.get(tag, 0) + len(samples)\n",
    "    for sample in samples:\n",
    "        test_samples.add(sample)\n",
    "print(len(test_samples))\n",
    "print(test_samples_count)\n",
    "print(tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "476ceb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organization : 0.19675867308179285\n",
      "building : 0.19762638896968993\n",
      "art : 0.19367308299147995\n",
      "person : 0.19411107507117886\n",
      "product : 0.19761846001974334\n",
      "other : 0.19889760440958237\n",
      "event : 0.19769138914687542\n",
      "location : 0.19660735826296744\n"
     ]
    }
   ],
   "source": [
    "for tag in test_samples_count:\n",
    "    print(tag, ':', test_samples_count[tag] / tag_count[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510020fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeb5a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./supervised/coarse/train.txt', encoding='utf-8', mode='w') as f:\n",
    "    f.writelines('\\n\\n'.join(list(train_samples)))\n",
    "with open('./supervised/coarse/dev.txt', encoding='utf-8', mode='w') as f:\n",
    "    f.writelines('\\n\\n'.join(list(valid_samples)))\n",
    "with open('./supervised/coarse/test.txt', encoding='utf-8', mode='w') as f:\n",
    "    f.writelines('\\n\\n'.join(list(test_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5eb265-0e1a-4f2c-baff-79c271d97761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
