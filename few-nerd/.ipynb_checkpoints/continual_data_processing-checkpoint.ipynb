{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f7c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "parent_dir = 'supervised/supervised/'\n",
    "file_list = [os.path.join(parent_dir, file) for file in os.listdir(parent_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fcd65be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188239\n"
     ]
    }
   ],
   "source": [
    "raw_lines = []\n",
    "for file in file_list:\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    lines[-1] = lines[-1] + '\\n'\n",
    "    lines.extend(['\\n'])\n",
    "    lines = [line.strip() for line in lines]\n",
    "    raw_lines.extend(lines)\n",
    "\n",
    "all_sentences = []\n",
    "beg, end = 0, 0\n",
    "while end < len(raw_lines):\n",
    "        if raw_lines[end]:\n",
    "            end += 1\n",
    "        else:\n",
    "            sentence = raw_lines[beg:end]\n",
    "            all_sentences.append(sentence)\n",
    "            end += 1\n",
    "            beg = end\n",
    "print(len(all_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129b7c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154387\n"
     ]
    }
   ],
   "source": [
    "washed_sentences = set()\n",
    "for sentence in all_sentences:\n",
    "    O_count = sum([1 if wt.endswith('\\tO') else 0 for wt in sentence])\n",
    "    if O_count != len(sentence):\n",
    "        washed_sentences.add('\\n'.join(sentence))\n",
    "print(len(washed_sentences))\n",
    "all_sentences = list(washed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7dad152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarse-grained classes: {'other', 'building', 'person', 'organization', 'event', 'art', 'product', 'location'}; \n",
      "fine-grained classes: {'building-hotel', 'building-restaurant', 'building-library', 'art-broadcastprogram', 'organization-media,newspaper', 'other-educationaldegree', 'location-road,railway,highway,transit', 'other-astronomything', 'other-law', 'person-athlete', 'building-other', 'organization-education', 'organization-showorganization', 'person-director', 'organization-company', 'event-election', 'other-livingthing', 'product-game', 'other-chemicalthing', 'other-medical', 'product-weapon', 'product-car', 'person-other', 'product-software', 'product-food', 'art-film', 'person-artist,author', 'other-biologything', 'organization-sportsleague', 'product-other', 'other-disease', 'product-ship', 'event-sportsevent', 'product-airplane', 'building-theater', 'art-other', 'organization-politicalparty', 'organization-other', 'building-airport', 'product-train', 'organization-government,governmentagency', 'location-bodiesofwater', 'event-attack,battle,war,militaryconflict', 'building-sportsfacility', 'location-GPE', 'event-protest', 'art-painting', 'organization-sportsteam', 'person-scholar', 'art-writtenart', 'event-disaster', 'building-hospital', 'art-music', 'other-language', 'event-other', 'location-island', 'other-god', 'person-actor', 'location-other', 'organization-religion', 'other-currency', 'person-soldier', 'other-award', 'location-park', 'person-politician', 'location-mountain'}\n",
      "Tiamat\tperson\n",
      "appears\tO\n",
      "in\tO\n",
      "a\tO\n",
      "preview\tO\n",
      "article\tO\n",
      "for\tO\n",
      "the\tO\n",
      "third\tO\n",
      "edition\tO\n",
      ",\tO\n",
      "in\tO\n",
      "``\tO\n",
      "Dragon\tart\n",
      "``\tO\n",
      "#\tO\n",
      "272\tO\n",
      "(\tO\n",
      "June\tO\n",
      "2000\tO\n",
      ")\tO\n",
      ".\tO\n"
     ]
    }
   ],
   "source": [
    "coarse_classes = set()\n",
    "fine_classes = set()\n",
    "for k in range(len(all_sentences)):\n",
    "    wts = all_sentences[k].split('\\n')\n",
    "    for i in range(len(wts)):\n",
    "        word_tag = wts[i]\n",
    "        tokens = word_tag.split('\\t')\n",
    "        if tokens[1] != 'O':\n",
    "            if '/' in tokens[1]:\n",
    "                tokens[1] = tokens[1].replace('/', ',')\n",
    "                wts[i] = '\\t'.join(tokens)\n",
    "            fine_classes.add(tokens[1])\n",
    "            coarse_classes.add(tokens[1].split('-')[0])\n",
    "    all_sentences[k] = '\\n'.join(wts)\n",
    "print(f'coarse-grained classes: {coarse_classes}; \\nfine-grained classes: {fine_classes}')\n",
    "\n",
    "coarse_dict = {}\n",
    "fine_dict = {}\n",
    "\n",
    "coarse_sid_dict = {}\n",
    "fine_sid_dict = {}\n",
    "\n",
    "coarse_sentences = ['\\n'.join([wt.replace(wt.split('\\t')[1], wt.split('\\t')[1].split('-')[0]) for wt in sentence.split('\\n')]) for sentence in all_sentences]\n",
    "print(coarse_sentences[0])\n",
    "\n",
    "for coarse_class in coarse_classes:\n",
    "    sentences = []\n",
    "    sid_list = []\n",
    "    out_sid = 0\n",
    "    for sentence in coarse_sentences:\n",
    "        wts = sentence.split('\\n')\n",
    "        for word_tag in wts:\n",
    "            if word_tag.endswith(coarse_class):\n",
    "                sentences.append(sentence)\n",
    "                sid_list.append(out_sid)\n",
    "                break\n",
    "        out_sid += 1\n",
    "    coarse_dict[coarse_class] = sentences\n",
    "    coarse_sid_dict[coarse_class] = sid_list\n",
    "\n",
    "for fine_class in fine_classes:\n",
    "    sentences = []\n",
    "    sid_list = []\n",
    "    out_sid = 0\n",
    "    for sentence in all_sentences:\n",
    "        wts = sentence.split('\\n')\n",
    "        for word_tag in wts:\n",
    "            if word_tag.endswith(fine_class):\n",
    "                sentences.append(sentence)\n",
    "                sid_list.append(out_sid)\n",
    "                break\n",
    "        out_sid += 1\n",
    "    fine_dict[fine_class] = sentences\n",
    "    fine_sid_dict[fine_class] = sid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c62c7e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'other': 20353, 'building': 14977, 'person': 28527, 'organization': 29173, 'event': 14490, 'art': 12676, 'product': 14480, 'location': 19711}\n",
      "{'building-hotel': 1079, 'building-restaurant': 770, 'building-library': 1273, 'art-broadcastprogram': 1903, 'organization-media,newspaper': 2596, 'other-educationaldegree': 1175, 'location-road,railway,highway,transit': 3607, 'other-astronomything': 1663, 'other-law': 1782, 'person-athlete': 4584, 'building-other': 4647, 'organization-education': 3970, 'organization-showorganization': 1909, 'person-director': 1667, 'organization-company': 5354, 'event-election': 719, 'other-livingthing': 1923, 'product-game': 1319, 'other-chemicalthing': 2142, 'other-medical': 1198, 'product-weapon': 1474, 'product-car': 1768, 'person-other': 8423, 'product-software': 1912, 'product-food': 1044, 'art-film': 1704, 'person-artist,author': 3081, 'other-biologything': 2677, 'organization-sportsleague': 2756, 'product-other': 3111, 'other-disease': 1909, 'product-ship': 1401, 'event-sportsevent': 3345, 'product-airplane': 2059, 'building-theater': 1551, 'art-other': 1529, 'organization-politicalparty': 2558, 'organization-other': 6008, 'building-airport': 1279, 'product-train': 992, 'organization-government,governmentagency': 3285, 'location-bodiesofwater': 2703, 'event-attack,battle,war,militaryconflict': 2539, 'building-sportsfacility': 1547, 'location-GPE': 9873, 'event-protest': 675, 'art-painting': 213, 'organization-sportsteam': 2810, 'person-scholar': 2001, 'art-writtenart': 2145, 'event-disaster': 877, 'building-hospital': 1239, 'art-music': 1975, 'other-language': 1906, 'event-other': 2127, 'location-island': 1879, 'other-god': 1247, 'person-actor': 1659, 'location-other': 2924, 'organization-religion': 1972, 'other-currency': 1906, 'person-soldier': 1996, 'other-award': 2009, 'location-park': 1520, 'person-politician': 3716, 'location-mountain': 1783}\n"
     ]
    }
   ],
   "source": [
    "# remove duplicated sentences among different classes\n",
    "key_list = list(coarse_sid_dict.keys())\n",
    "for i in range(len(key_list)):\n",
    "    a_sids = set(coarse_sid_dict[key_list[i]])\n",
    "    for j in range(i + 1, len(key_list)):\n",
    "        b_sids = set(coarse_sid_dict[key_list[j]])\n",
    "        c = a_sids.intersection(b_sids)\n",
    "        m, n = len(a_sids), len(b_sids)\n",
    "        for sid in c:\n",
    "            removed_sentence = coarse_sentences[sid]\n",
    "            if m > n:\n",
    "                coarse_dict[key_list[i]].remove(removed_sentence)\n",
    "                coarse_sid_dict[key_list[i]].remove(sid)\n",
    "                a_sids.remove(sid)\n",
    "                m -= 1\n",
    "            else:\n",
    "                coarse_dict[key_list[j]].remove(removed_sentence)\n",
    "                coarse_sid_dict[key_list[j]].remove(sid)\n",
    "                b_sids.remove(sid)\n",
    "                n -= 1\n",
    "\n",
    "total_sentence_num = 0\n",
    "\n",
    "# remove duplicated sentences among different classes\n",
    "key_list = list(fine_sid_dict.keys())\n",
    "for i in range(len(key_list)):\n",
    "    a_sids = set(fine_sid_dict[key_list[i]])\n",
    "    for j in range(i + 1, len(key_list)):\n",
    "        b_sids = set(fine_sid_dict[key_list[j]])\n",
    "        c = a_sids.intersection(b_sids)\n",
    "        m, n = len(a_sids), len(b_sids)\n",
    "        for sid in c:\n",
    "            removed_sentence = all_sentences[sid]\n",
    "            if m > n:\n",
    "                fine_dict[key_list[i]].remove(removed_sentence)\n",
    "                fine_sid_dict[key_list[i]].remove(sid)\n",
    "                a_sids.remove(sid)\n",
    "                m -= 1\n",
    "            else:\n",
    "                fine_dict[key_list[j]].remove(removed_sentence)\n",
    "                fine_sid_dict[key_list[j]].remove(sid)\n",
    "                b_sids.remove(sid)\n",
    "                n -= 1\n",
    "\n",
    "coarse_tag_count, fine_tag_count = {}, {}\n",
    "for c in coarse_classes:\n",
    "    coarse_tag_count[c] = len(coarse_dict[c])\n",
    "for c in fine_classes:\n",
    "    fine_tag_count[c] = len(fine_dict[c])\n",
    "print(coarse_tag_count)\n",
    "print(fine_tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd461f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "corse_distribution = {}\n",
    "for c in coarse_dict:\n",
    "    distribution = {}\n",
    "    for s in coarse_dict[c]:\n",
    "        t_set = set()\n",
    "        for w_t in s.split('\\n'):\n",
    "            t = w_t.split('\\t')[1] \n",
    "            if t != 'O':\n",
    "                t_set.add(t.split('-')[0])\n",
    "        for t in t_set:\n",
    "            distribution[t] = distribution.get(t, 0) + 1\n",
    "    corse_distribution[c] = distribution\n",
    "with open('./continual/coarse/distribution.json', encoding='utf-8', mode='w') as f:\n",
    "    json.dump(corse_distribution, f)\n",
    "\n",
    "fine_distribution = {}\n",
    "for c in fine_dict:\n",
    "    distribution = {}\n",
    "    for s in fine_dict[c]:\n",
    "        t_set = set()\n",
    "        for w_t in s.split('\\n'):\n",
    "            t = w_t.split('\\t')[1] \n",
    "            #\\ .split('-')[0]\n",
    "            if t != 'O':\n",
    "                t_set.add(t)\n",
    "        for t in t_set:\n",
    "            distribution[t] = distribution.get(t, 0) + 1\n",
    "    fine_distribution[c] = distribution\n",
    "\n",
    "with open('./continual/fine/distribution.json', encoding='utf-8', mode='w') as f:\n",
    "    json.dump(fine_distribution, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba69760",
   "metadata": {},
   "outputs": [],
   "source": [
    "del washed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "674ef47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecca2289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In\tO\n",
      "August\tO\n",
      "1932\tO\n",
      ",\tO\n",
      "Nichols\tO\n",
      "hanged\tO\n",
      "himself\tO\n",
      "in\tO\n",
      "a\tO\n",
      "suite\tO\n",
      "at\tO\n",
      "the\tO\n",
      "Pierre\tbuilding-hotel\n",
      "Hotel\tbuilding-hotel\n",
      "in\tO\n",
      "New\tO\n",
      "York\tO\n",
      ".\tO\n"
     ]
    }
   ],
   "source": [
    "no_coarse_dict, no_fine_dict = {}, {}\n",
    "for coarse in coarse_classes:\n",
    "    sample_ids = coarse_sid_dict[coarse]\n",
    "    no_samples = []\n",
    "    for sample_id in sample_ids:\n",
    "        sample = coarse_sentences[sample_id]\n",
    "        wts = sample.split('\\n')\n",
    "        for i in range(len(wts)):\n",
    "            word_tag = wts[i].split('\\t')\n",
    "            if word_tag[1] != 'O' and word_tag[1] != coarse:\n",
    "                word_tag[1] = 'O'\n",
    "                wts[i] = '\\t'.join(word_tag)\n",
    "        no_samples.append('\\n'.join(wts))\n",
    "    no_coarse_dict[coarse] = no_samples\n",
    "for fine in fine_classes:\n",
    "    sample_ids = fine_sid_dict[fine]\n",
    "    no_samples = []\n",
    "    for sample_id in sample_ids:\n",
    "        sample = all_sentences[sample_id]\n",
    "        wts = sample.split('\\n')\n",
    "        for i in range(len(wts)):\n",
    "            word_tag = wts[i].split('\\t')\n",
    "            if word_tag[1] != 'O' and word_tag[1] != fine:\n",
    "                word_tag[1] = 'O'\n",
    "                wts[i] = '\\t'.join(word_tag)\n",
    "        no_samples.append('\\n'.join(wts))\n",
    "    no_fine_dict[fine] = no_samples\n",
    "for v in no_fine_dict.values():\n",
    "    print(v[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "320dce3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other : train : 16283; test : 4070; total : 20353; ratio : 0.8000294796835847\n",
      "building : train : 11982; test : 2995; total : 14977; ratio : 0.8000267076183482\n",
      "person : train : 22822; test : 5705; total : 28527; ratio : 0.800014021803905\n",
      "organization : train : 23339; test : 5834; total : 29173; ratio : 0.8000205669626024\n",
      "event : train : 11592; test : 2898; total : 14490; ratio : 0.8\n",
      "art : train : 10141; test : 2535; total : 12676; ratio : 0.8000157778479016\n",
      "product : train : 11584; test : 2896; total : 14480; ratio : 0.8\n",
      "location : train : 15769; test : 3942; total : 19711; ratio : 0.8000101466186393\n",
      "building-hotel : train : 864; test : 215; total : 1079; ratio : 0.8007414272474513\n",
      "building-restaurant : train : 616; test : 154; total : 770; ratio : 0.8\n",
      "building-library : train : 1019; test : 254; total : 1273; ratio : 0.800471327572663\n",
      "art-broadcastprogram : train : 1523; test : 380; total : 1903; ratio : 0.8003152916447714\n",
      "organization-media,newspaper : train : 2077; test : 519; total : 2596; ratio : 0.8000770416024653\n",
      "other-educationaldegree : train : 940; test : 235; total : 1175; ratio : 0.8\n",
      "location-road,railway,highway,transit : train : 2886; test : 721; total : 3607; ratio : 0.8001108954810091\n",
      "other-astronomything : train : 1331; test : 332; total : 1663; ratio : 0.8003607937462417\n",
      "other-law : train : 1426; test : 356; total : 1782; ratio : 0.8002244668911336\n",
      "person-athlete : train : 3668; test : 916; total : 4584; ratio : 0.800174520069808\n",
      "building-other : train : 3718; test : 929; total : 4647; ratio : 0.8000860770389498\n",
      "organization-education : train : 3176; test : 794; total : 3970; ratio : 0.8\n",
      "organization-showorganization : train : 1528; test : 381; total : 1909; ratio : 0.8004190675746464\n",
      "person-director : train : 1334; test : 333; total : 1667; ratio : 0.8002399520095981\n",
      "organization-company : train : 4284; test : 1070; total : 5354; ratio : 0.8001494209936496\n",
      "event-election : train : 576; test : 143; total : 719; ratio : 0.8011126564673157\n",
      "other-livingthing : train : 1539; test : 384; total : 1923; ratio : 0.8003120124804992\n",
      "product-game : train : 1056; test : 263; total : 1319; ratio : 0.800606520090978\n",
      "other-chemicalthing : train : 1714; test : 428; total : 2142; ratio : 0.800186741363212\n",
      "other-medical : train : 959; test : 239; total : 1198; ratio : 0.8005008347245409\n",
      "product-weapon : train : 1180; test : 294; total : 1474; ratio : 0.8005427408412483\n",
      "product-car : train : 1415; test : 353; total : 1768; ratio : 0.8003393665158371\n",
      "person-other : train : 6739; test : 1684; total : 8423; ratio : 0.8000712335272469\n",
      "product-software : train : 1530; test : 382; total : 1912; ratio : 0.8002092050209205\n",
      "product-food : train : 836; test : 208; total : 1044; ratio : 0.8007662835249042\n",
      "art-film : train : 1364; test : 340; total : 1704; ratio : 0.8004694835680751\n",
      "person-artist,author : train : 2465; test : 616; total : 3081; ratio : 0.8000649139889646\n",
      "other-biologything : train : 2142; test : 535; total : 2677; ratio : 0.8001494209936496\n",
      "organization-sportsleague : train : 2205; test : 551; total : 2756; ratio : 0.8000725689404935\n",
      "product-other : train : 2489; test : 622; total : 3111; ratio : 0.8000642880102861\n",
      "other-disease : train : 1528; test : 381; total : 1909; ratio : 0.8004190675746464\n",
      "product-ship : train : 1121; test : 280; total : 1401; ratio : 0.8001427551748751\n",
      "event-sportsevent : train : 2676; test : 669; total : 3345; ratio : 0.8\n",
      "product-airplane : train : 1648; test : 411; total : 2059; ratio : 0.8003885381253035\n",
      "building-theater : train : 1241; test : 310; total : 1551; ratio : 0.8001289490651193\n",
      "art-other : train : 1224; test : 305; total : 1529; ratio : 0.8005232177894048\n",
      "organization-politicalparty : train : 2047; test : 511; total : 2558; ratio : 0.8002345582486318\n",
      "organization-other : train : 4807; test : 1201; total : 6008; ratio : 0.8000998668442078\n",
      "building-airport : train : 1024; test : 255; total : 1279; ratio : 0.800625488663018\n",
      "product-train : train : 794; test : 198; total : 992; ratio : 0.8004032258064516\n",
      "organization-government,governmentagency : train : 2628; test : 657; total : 3285; ratio : 0.8\n",
      "location-bodiesofwater : train : 2163; test : 540; total : 2703; ratio : 0.8002219755826859\n",
      "event-attack,battle,war,militaryconflict : train : 2032; test : 507; total : 2539; ratio : 0.8003150846790075\n",
      "building-sportsfacility : train : 1238; test : 309; total : 1547; ratio : 0.8002585649644474\n",
      "location-GPE : train : 7899; test : 1974; total : 9873; ratio : 0.800060771801884\n",
      "event-protest : train : 540; test : 135; total : 675; ratio : 0.8\n",
      "art-painting : train : 171; test : 42; total : 213; ratio : 0.8028169014084507\n",
      "organization-sportsteam : train : 2248; test : 562; total : 2810; ratio : 0.8\n",
      "person-scholar : train : 1601; test : 400; total : 2001; ratio : 0.8000999500249875\n",
      "art-writtenart : train : 1716; test : 429; total : 2145; ratio : 0.8\n",
      "event-disaster : train : 702; test : 175; total : 877; ratio : 0.8004561003420753\n",
      "building-hospital : train : 992; test : 247; total : 1239; ratio : 0.8006456820016142\n",
      "art-music : train : 1580; test : 395; total : 1975; ratio : 0.8\n",
      "other-language : train : 1525; test : 381; total : 1906; ratio : 0.8001049317943337\n",
      "event-other : train : 1702; test : 425; total : 2127; ratio : 0.8001880582980724\n",
      "location-island : train : 1504; test : 375; total : 1879; ratio : 0.8004257583821182\n",
      "other-god : train : 998; test : 249; total : 1247; ratio : 0.8003207698476343\n",
      "person-actor : train : 1328; test : 331; total : 1659; ratio : 0.8004822182037372\n",
      "location-other : train : 2340; test : 584; total : 2924; ratio : 0.8002735978112175\n",
      "organization-religion : train : 1578; test : 394; total : 1972; ratio : 0.8002028397565923\n",
      "other-currency : train : 1525; test : 381; total : 1906; ratio : 0.8001049317943337\n",
      "person-soldier : train : 1597; test : 399; total : 1996; ratio : 0.8001002004008017\n",
      "other-award : train : 1608; test : 401; total : 2009; ratio : 0.8003982080637133\n",
      "location-park : train : 1216; test : 304; total : 1520; ratio : 0.8\n",
      "person-politician : train : 2973; test : 743; total : 3716; ratio : 0.80005382131324\n",
      "location-mountain : train : 1427; test : 356; total : 1783; ratio : 0.8003365114974762\n"
     ]
    }
   ],
   "source": [
    "no_coarse_train_samples, no_coarse_test_samples = {}, {}\n",
    "no_coarse_train_indices, no_coarse_test_indices = {}, {}\n",
    "no_fine_train_samples, no_fine_test_samples = {}, {}\n",
    "no_fine_train_indices, no_fine_test_indices = {}, {}\n",
    "\n",
    "for c in coarse_classes:\n",
    "    sample_ids = coarse_sid_dict[c]\n",
    "    train_sample_id_indices = set()\n",
    "    count = 0\n",
    "    while count < 0.8 * coarse_tag_count[c]:\n",
    "        sample_id_idx = random.choice(range(len(sample_ids)))\n",
    "        if sample_id_idx not in train_sample_id_indices:\n",
    "            train_sample_id_indices.add(sample_id_idx)\n",
    "            count += 1\n",
    "    test_sample_id_indices = set(range(len(sample_ids))).difference(train_sample_id_indices)\n",
    "    no_coarse_train_samples[c] = [no_coarse_dict[c][sample_id_idx] for sample_id_idx in train_sample_id_indices]\n",
    "    no_coarse_test_samples[c] = [no_coarse_dict[c][sample_id_idx] for sample_id_idx in test_sample_id_indices]\n",
    "    no_coarse_train_indices[c] = train_sample_id_indices\n",
    "    no_coarse_test_indices[c] = test_sample_id_indices\n",
    "for c in coarse_tag_count:\n",
    "    print(f'{c} : train : {len(no_coarse_train_samples[c])}; test : {len(no_coarse_test_samples[c])}; total : {coarse_tag_count[c]}; ratio : {len(no_coarse_train_samples[c]) / coarse_tag_count[c]}')\n",
    "\n",
    "for c in fine_classes:\n",
    "    sample_ids = fine_sid_dict[c]\n",
    "    train_sample_id_indices = set()\n",
    "    count = 0\n",
    "    while count < 0.8 * fine_tag_count[c]:\n",
    "        sample_id_idx = random.choice(range(len(sample_ids)))\n",
    "        if sample_id_idx not in train_sample_id_indices:\n",
    "            train_sample_id_indices.add(sample_id_idx)\n",
    "            count += 1\n",
    "    test_sample_id_indices = set(range(len(sample_ids))).difference(train_sample_id_indices)\n",
    "    no_fine_train_samples[c] = [no_fine_dict[c][sample_id_idx] for sample_id_idx in train_sample_id_indices]\n",
    "    no_fine_test_samples[c] = [no_fine_dict[c][sample_id_idx] for sample_id_idx in test_sample_id_indices]\n",
    "    no_fine_train_indices[c] = train_sample_id_indices\n",
    "    no_fine_test_indices[c] = test_sample_id_indices\n",
    "for c in fine_tag_count:\n",
    "    print(f'{c} : train : {len(no_fine_train_samples[c])}; test : {len(no_fine_test_samples[c])}; total : {fine_tag_count[c]}; ratio : {len(no_fine_train_samples[c]) / fine_tag_count[c]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6eb3cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building-hotel : train : 864; total : 1079; ratio : 0.8007414272474513\n",
      "building-restaurant : train : 616; total : 770; ratio : 0.8\n",
      "building-library : train : 1019; total : 1273; ratio : 0.800471327572663\n",
      "art-broadcastprogram : train : 1523; total : 1903; ratio : 0.8003152916447714\n",
      "organization-media,newspaper : train : 2077; total : 2596; ratio : 0.8000770416024653\n",
      "other-educationaldegree : train : 940; total : 1175; ratio : 0.8\n",
      "location-road,railway,highway,transit : train : 2886; total : 3607; ratio : 0.8001108954810091\n",
      "other-astronomything : train : 1331; total : 1663; ratio : 0.8003607937462417\n",
      "other-law : train : 1426; total : 1782; ratio : 0.8002244668911336\n",
      "person-athlete : train : 3668; total : 4584; ratio : 0.800174520069808\n",
      "building-other : train : 3718; total : 4647; ratio : 0.8000860770389498\n",
      "organization-education : train : 3176; total : 3970; ratio : 0.8\n",
      "organization-showorganization : train : 1528; total : 1909; ratio : 0.8004190675746464\n",
      "person-director : train : 1334; total : 1667; ratio : 0.8002399520095981\n",
      "organization-company : train : 4284; total : 5354; ratio : 0.8001494209936496\n",
      "event-election : train : 576; total : 719; ratio : 0.8011126564673157\n",
      "other-livingthing : train : 1539; total : 1923; ratio : 0.8003120124804992\n",
      "product-game : train : 1056; total : 1319; ratio : 0.800606520090978\n",
      "other-chemicalthing : train : 1714; total : 2142; ratio : 0.800186741363212\n",
      "other-medical : train : 959; total : 1198; ratio : 0.8005008347245409\n",
      "product-weapon : train : 1180; total : 1474; ratio : 0.8005427408412483\n",
      "product-car : train : 1415; total : 1768; ratio : 0.8003393665158371\n",
      "person-other : train : 6739; total : 8423; ratio : 0.8000712335272469\n",
      "product-software : train : 1530; total : 1912; ratio : 0.8002092050209205\n",
      "product-food : train : 836; total : 1044; ratio : 0.8007662835249042\n",
      "art-film : train : 1364; total : 1704; ratio : 0.8004694835680751\n",
      "person-artist,author : train : 2465; total : 3081; ratio : 0.8000649139889646\n",
      "other-biologything : train : 2142; total : 2677; ratio : 0.8001494209936496\n",
      "organization-sportsleague : train : 2205; total : 2756; ratio : 0.8000725689404935\n",
      "product-other : train : 2489; total : 3111; ratio : 0.8000642880102861\n",
      "other-disease : train : 1528; total : 1909; ratio : 0.8004190675746464\n",
      "product-ship : train : 1121; total : 1401; ratio : 0.8001427551748751\n",
      "event-sportsevent : train : 2676; total : 3345; ratio : 0.8\n",
      "product-airplane : train : 1648; total : 2059; ratio : 0.8003885381253035\n",
      "building-theater : train : 1241; total : 1551; ratio : 0.8001289490651193\n",
      "art-other : train : 1224; total : 1529; ratio : 0.8005232177894048\n",
      "organization-politicalparty : train : 2047; total : 2558; ratio : 0.8002345582486318\n",
      "organization-other : train : 4807; total : 6008; ratio : 0.8000998668442078\n",
      "building-airport : train : 1024; total : 1279; ratio : 0.800625488663018\n",
      "product-train : train : 794; total : 992; ratio : 0.8004032258064516\n",
      "organization-government,governmentagency : train : 2628; total : 3285; ratio : 0.8\n",
      "location-bodiesofwater : train : 2163; total : 2703; ratio : 0.8002219755826859\n",
      "event-attack,battle,war,militaryconflict : train : 2032; total : 2539; ratio : 0.8003150846790075\n",
      "building-sportsfacility : train : 1238; total : 1547; ratio : 0.8002585649644474\n",
      "location-GPE : train : 7899; total : 9873; ratio : 0.800060771801884\n",
      "event-protest : train : 540; total : 675; ratio : 0.8\n",
      "art-painting : train : 171; total : 213; ratio : 0.8028169014084507\n",
      "organization-sportsteam : train : 2248; total : 2810; ratio : 0.8\n",
      "person-scholar : train : 1601; total : 2001; ratio : 0.8000999500249875\n",
      "art-writtenart : train : 1716; total : 2145; ratio : 0.8\n",
      "event-disaster : train : 702; total : 877; ratio : 0.8004561003420753\n",
      "building-hospital : train : 992; total : 1239; ratio : 0.8006456820016142\n",
      "art-music : train : 1580; total : 1975; ratio : 0.8\n",
      "other-language : train : 1525; total : 1906; ratio : 0.8001049317943337\n",
      "event-other : train : 1702; total : 2127; ratio : 0.8001880582980724\n",
      "location-island : train : 1504; total : 1879; ratio : 0.8004257583821182\n",
      "other-god : train : 998; total : 1247; ratio : 0.8003207698476343\n",
      "person-actor : train : 1328; total : 1659; ratio : 0.8004822182037372\n",
      "location-other : train : 2340; total : 2924; ratio : 0.8002735978112175\n",
      "organization-religion : train : 1578; total : 1972; ratio : 0.8002028397565923\n",
      "other-currency : train : 1525; total : 1906; ratio : 0.8001049317943337\n",
      "person-soldier : train : 1597; total : 1996; ratio : 0.8001002004008017\n",
      "other-award : train : 1608; total : 2009; ratio : 0.8003982080637133\n",
      "location-park : train : 1216; total : 1520; ratio : 0.8\n",
      "person-politician : train : 2973; total : 3716; ratio : 0.80005382131324\n",
      "location-mountain : train : 1427; total : 1783; ratio : 0.8003365114974762\n",
      "No satisfied sample. Exit search.\n",
      "No satisfied sample. Exit search.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6576/2093011925.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mvisited\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mtest_tag_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_tag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.25\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtrain_dist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_tag\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtrain_dist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_tag\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mtest_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremained_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mvisited\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvisited\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mremained_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\py38\\lib\\random.py\u001b[0m in \u001b[0;36mchoice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;34m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "coarse_train_samples, fine_test_samples = {}, {}\n",
    "fine_train_samples, fine_test_samples = {}, {}\n",
    "for c in coarse_classses:\n",
    "    train_samples = [coarse_dict[c][i] for i in no_coarse_train_indices[c]]\n",
    "    coarse_train_samples[c] = train_samples\n",
    "for c in fine_tag_count:\n",
    "    print(f'{c} : train : {len(coarse_train_samples[c])}; total : {coarse_tag_count[c]}; ratio : {len(coarse_train_samples[c]) / coarse_tag_count[c]}')\n",
    "# remained_samples = set()\n",
    "for c in fine_classes:\n",
    "    train_samples = [fine_dict[c][i] for i in no_fine_train_indices[c]]\n",
    "    fine_train_samples[c] = train_samples\n",
    "#     remained_samples = remained_samples.union(set([fine_dict[c][i] for i in no_fine_test_indices[c]]))\n",
    "for c in fine_tag_count:\n",
    "    print(f'{c} : train : {len(fine_train_samples[c])}; total : {fine_tag_count[c]}; ratio : {len(fine_train_samples[c]) / fine_tag_count[c]}')\n",
    "\n",
    "# for c in fine_tag_count:\n",
    "#     train_samples = fine_train_samples[c]\n",
    "#     train_dist = {}\n",
    "#     for train_sample in train_samples:\n",
    "#         tags = set(wt .split('\\t')[1] for wt in train_sample.split('\\n'))\n",
    "#         tags.remove('O')\n",
    "#         for tag in tags:\n",
    "#             train_dist[tag] = train_dist.get(tag, 0) + 1\n",
    "#     test_samples, test_tag_count = set(), {}\n",
    "#     for train_tag in train_dist:\n",
    "#         visited = set()\n",
    "#         while test_tag_count.get(train_tag, 0) < (0.25 * train_dist[train_tag] if train_dist[train_tag] > 4 else 1):\n",
    "#             test_sample = random.choice(list(remained_samples))\n",
    "#             visited.add(test_sample)\n",
    "#             if visited == remained_samples:\n",
    "#                 print('No satisfied sample. Exit search.')\n",
    "#                 break\n",
    "#             if test_sample not in test_samples and test_sample not in train_samples:\n",
    "#                 satisfied = True\n",
    "#                 tags = set([wt.split('\\t')[1] for wt in test_sample.split('\\n')])\n",
    "#                 tags.remove('O')\n",
    "#                 if tags.issubset(train_dist.keys()):\n",
    "#                     for t in tags:\n",
    "#                         if test_tag_count.get(t, 0) + 1 > (0.25 * train_dist[t] if train_dist[t] > 4 else 1):\n",
    "#                             satisfied = False\n",
    "#                             break\n",
    "#                 else:\n",
    "#                     satisfied = False\n",
    "#                 if satisfied:\n",
    "#                     test_samples.add(test_sample)\n",
    "#                     remained_samples.remove(test_sample)\n",
    "#                     visited.remove(test_sample)\n",
    "#                     test_tag_count[train_tag] = test_tag_count.get(train_tag, 0) + 1\n",
    "#                     for t in tags:\n",
    "#                         if t != 'O' and t != train_tag:\n",
    "#                             test_tag_count[t] = test_tag_count.get(t, 0) + 1\n",
    "#     fine_test_samples[c] = test_samples\n",
    "#     print(f'{c} test samples found!')\n",
    "# for c in tag_count:\n",
    "#     print(f'{c} : test : {len(fine_test_samples[c])}; total : {fine_tag_count[c]}; ratio : {len(fine_test_samples[c]) / fine_tag_count[c]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6be2147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(parent_dir, samples_dict, mode):\n",
    "    for fname in samples_dict:\n",
    "        path = os.path.join(parent_dir, fname)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        with open(os.path.join(path, mode+'.txt'), 'w', encoding='utf-8') as f:\n",
    "            f.writelines('\\n\\n'.join(samples_dict[fname]))\n",
    "save_file('./continual/coarse/non-overlapping', no_coarse_train_samples, mode='train')\n",
    "save_file('./continual/coarse/non-overlapping', no_coarse_test_samples, mode='test')\n",
    "save_file('./continual/fine/non-overlapping', no_fine_train_samples, mode='train')\n",
    "save_file('./continual/fine/non-overlapping', no_fine_test_samples, mode='test')\n",
    "save_file('./continual/fine/overlapping', fine_train_samples, mode='train')\n",
    "# save_file('./continual/fine/overlapping', fine_test_samples, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef7825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18771573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
