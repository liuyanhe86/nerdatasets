{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92edbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "parent_dir = 'supervised/supervised/'\n",
    "file_list = [os.path.join(parent_dir, file) for file in os.listdir(parent_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059e397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188239\n"
     ]
    }
   ],
   "source": [
    "raw_lines = []\n",
    "for file in file_list:\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    lines[-1] = lines[-1] + '\\n'\n",
    "    lines.extend(['\\n'])\n",
    "    lines = [line.strip() for line in lines]\n",
    "    raw_lines.extend(lines)\n",
    "\n",
    "all_sentences = []\n",
    "beg, end = 0, 0\n",
    "while end < len(raw_lines):\n",
    "        if raw_lines[end]:\n",
    "            end += 1\n",
    "        else:\n",
    "            sentence = raw_lines[beg:end]\n",
    "            all_sentences.append(sentence)\n",
    "            end += 1\n",
    "            beg = end\n",
    "print(len(all_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91375b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154387\n",
      "23482\n"
     ]
    }
   ],
   "source": [
    "washed_sentences = set()\n",
    "no_entities_sentences = set()\n",
    "for sentence in all_sentences:\n",
    "    O_count = sum([1 if wt.endswith('\\tO') else 0 for wt in sentence])\n",
    "    if O_count != len(sentence):\n",
    "        washed_sentences.add('\\n'.join(sentence))\n",
    "    else:\n",
    "        no_entities_sentences.add('\\n'.join(sentence))\n",
    "print(len(washed_sentences))\n",
    "print(len(no_entities_sentences))\n",
    "all_sentences = list(washed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696db900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarse-grained classes: {'building', 'product', 'art', 'location', 'organization', 'other', 'person', 'event'}; \n",
      "fine-grained classes: {'person-scholar', 'location-bodiesofwater', 'product-airplane', 'building-library', 'person-politician', 'person-athlete', 'other-chemicalthing', 'product-other', 'other-biologything', 'organization-showorganization', 'art-film', 'organization-other', 'building-other', 'organization-politicalparty', 'event-election', 'building-hotel', 'location-other', 'art-music', 'other-livingthing', 'product-game', 'building-sportsfacility', 'other-law', 'event-sportsevent', 'event-protest', 'building-restaurant', 'art-painting', 'other-language', 'location-road,railway,highway,transit', 'product-weapon', 'product-car', 'other-educationaldegree', 'person-artist,author', 'person-other', 'person-soldier', 'other-disease', 'other-astronomything', 'other-god', 'person-director', 'product-software', 'other-currency', 'art-writtenart', 'building-theater', 'organization-company', 'organization-sportsleague', 'organization-education', 'organization-government,governmentagency', 'event-other', 'art-broadcastprogram', 'location-park', 'event-attack,battle,war,militaryconflict', 'other-award', 'building-hospital', 'location-GPE', 'product-food', 'organization-religion', 'location-mountain', 'art-other', 'organization-sportsteam', 'organization-media,newspaper', 'product-ship', 'location-island', 'person-actor', 'building-airport', 'event-disaster', 'other-medical', 'product-train'}\n",
      "New\tO\n",
      "episodes\tO\n",
      "of\tO\n",
      "The\tO\n",
      "Skorpion\tart\n",
      "Show\tart\n",
      "are\tO\n",
      "posted\tO\n",
      "on\tO\n",
      "YouTube\tproduct\n",
      "weekly\tO\n",
      ".\tO\n"
     ]
    }
   ],
   "source": [
    "coarse_classes = set()\n",
    "fine_classes = set()\n",
    "for k in range(len(all_sentences)):\n",
    "    wts = all_sentences[k].split('\\n')\n",
    "    for i in range(len(wts)):\n",
    "        word_tag = wts[i]\n",
    "        tokens = word_tag.split('\\t')\n",
    "        if tokens[1] != 'O':\n",
    "            if '/' in tokens[1]:\n",
    "                tokens[1] = tokens[1].replace('/', ',')\n",
    "                wts[i] = '\\t'.join(tokens)\n",
    "            fine_classes.add(tokens[1])\n",
    "            coarse_classes.add(tokens[1].split('-')[0])\n",
    "    all_sentences[k] = '\\n'.join(wts)\n",
    "print(f'coarse-grained classes: {coarse_classes}; \\nfine-grained classes: {fine_classes}')\n",
    "\n",
    "coarse_dict = {}\n",
    "fine_dict = {}\n",
    "\n",
    "coarse_sid_dict = {}\n",
    "fine_sid_dict = {}\n",
    "\n",
    "coarse_sentences = ['\\n'.join([wt.replace(wt.split('\\t')[1], wt.split('\\t')[1].split('-')[0]) for wt in sentence.split('\\n')]) for sentence in all_sentences]\n",
    "print(coarse_sentences[0])\n",
    "\n",
    "for coarse_class in coarse_classes:\n",
    "    sentences = []\n",
    "    sid_list = []\n",
    "    out_sid = 0\n",
    "    for sentence in coarse_sentences:\n",
    "        wts = sentence.split('\\n')\n",
    "        for word_tag in wts:\n",
    "            if word_tag.endswith(coarse_class):\n",
    "                sentences.append(sentence)\n",
    "                sid_list.append(out_sid)\n",
    "                break\n",
    "        out_sid += 1\n",
    "    coarse_dict[coarse_class] = sentences\n",
    "    coarse_sid_dict[coarse_class] = sid_list\n",
    "\n",
    "for fine_class in fine_classes:\n",
    "    sentences = []\n",
    "    sid_list = []\n",
    "    out_sid = 0\n",
    "    for sentence in all_sentences:\n",
    "        wts = sentence.split('\\n')\n",
    "        for word_tag in wts:\n",
    "            if word_tag.endswith(fine_class):\n",
    "                sentences.append(sentence)\n",
    "                sid_list.append(out_sid)\n",
    "                break\n",
    "        out_sid += 1\n",
    "    fine_dict[fine_class] = sentences\n",
    "    fine_sid_dict[fine_class] = sid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a70da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'building': 14709, 'product': 15114, 'art': 12676, 'location': 29811, 'organization': 25248, 'other': 20353, 'person': 22352, 'event': 14124}\n",
      "{'person-scholar': 2067, 'location-bodiesofwater': 2872, 'product-airplane': 2079, 'building-library': 1276, 'person-politician': 4417, 'person-athlete': 4470, 'other-chemicalthing': 2116, 'product-other': 3158, 'other-biologything': 2677, 'organization-showorganization': 1952, 'art-film': 1745, 'organization-other': 5981, 'building-other': 4482, 'organization-politicalparty': 2614, 'event-election': 719, 'building-hotel': 1079, 'location-other': 3560, 'art-music': 2099, 'other-livingthing': 1926, 'product-game': 1319, 'building-sportsfacility': 1580, 'other-law': 1782, 'event-sportsevent': 4065, 'event-protest': 675, 'building-restaurant': 770, 'art-painting': 213, 'other-language': 1983, 'location-road,railway,highway,transit': 3523, 'product-weapon': 1474, 'product-car': 1775, 'other-educationaldegree': 1175, 'person-artist,author': 3172, 'person-other': 8423, 'person-soldier': 2049, 'other-disease': 1888, 'other-astronomything': 1663, 'other-god': 1247, 'person-director': 1651, 'product-software': 1912, 'other-currency': 1951, 'art-writtenart': 2243, 'building-theater': 1535, 'organization-company': 4818, 'organization-sportsleague': 2706, 'organization-education': 3253, 'organization-government,governmentagency': 3178, 'event-other': 2148, 'art-broadcastprogram': 1744, 'location-park': 1512, 'event-attack,battle,war,militaryconflict': 2458, 'other-award': 2106, 'building-hospital': 1236, 'location-GPE': 9873, 'product-food': 1044, 'organization-religion': 1973, 'location-mountain': 1858, 'art-other': 1528, 'organization-sportsteam': 2451, 'organization-media,newspaper': 2068, 'product-ship': 1401, 'location-island': 1727, 'person-actor': 1602, 'building-airport': 1279, 'event-disaster': 877, 'other-medical': 1198, 'product-train': 992}\n"
     ]
    }
   ],
   "source": [
    "# remove duplicated sentences among different classes\n",
    "key_list = list(coarse_sid_dict.keys())\n",
    "for i in range(len(key_list)):\n",
    "    a_sids = set(coarse_sid_dict[key_list[i]])\n",
    "    for j in range(i + 1, len(key_list)):\n",
    "        b_sids = set(coarse_sid_dict[key_list[j]])\n",
    "        c = a_sids.intersection(b_sids)\n",
    "        m, n = len(a_sids), len(b_sids)\n",
    "        for sid in c:\n",
    "            removed_sentence = coarse_sentences[sid]\n",
    "            if m > n:\n",
    "                coarse_dict[key_list[i]].remove(removed_sentence)\n",
    "                coarse_sid_dict[key_list[i]].remove(sid)\n",
    "                a_sids.remove(sid)\n",
    "                m -= 1\n",
    "            else:\n",
    "                coarse_dict[key_list[j]].remove(removed_sentence)\n",
    "                coarse_sid_dict[key_list[j]].remove(sid)\n",
    "                b_sids.remove(sid)\n",
    "                n -= 1\n",
    "\n",
    "total_sentence_num = 0\n",
    "\n",
    "# remove duplicated sentences among different classes\n",
    "key_list = list(fine_sid_dict.keys())\n",
    "for i in range(len(key_list)):\n",
    "    a_sids = set(fine_sid_dict[key_list[i]])\n",
    "    for j in range(i + 1, len(key_list)):\n",
    "        b_sids = set(fine_sid_dict[key_list[j]])\n",
    "        c = a_sids.intersection(b_sids)\n",
    "        m, n = len(a_sids), len(b_sids)\n",
    "        for sid in c:\n",
    "            removed_sentence = all_sentences[sid]\n",
    "            if m > n:\n",
    "                fine_dict[key_list[i]].remove(removed_sentence)\n",
    "                fine_sid_dict[key_list[i]].remove(sid)\n",
    "                a_sids.remove(sid)\n",
    "                m -= 1\n",
    "            else:\n",
    "                fine_dict[key_list[j]].remove(removed_sentence)\n",
    "                fine_sid_dict[key_list[j]].remove(sid)\n",
    "                b_sids.remove(sid)\n",
    "                n -= 1\n",
    "\n",
    "coarse_tag_count, fine_tag_count = {}, {}\n",
    "for c in coarse_classes:\n",
    "    coarse_tag_count[c] = len(coarse_dict[c])\n",
    "for c in fine_classes:\n",
    "    fine_tag_count[c] = len(fine_dict[c])\n",
    "print(coarse_tag_count)\n",
    "print(fine_tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d230ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "corse_distribution = {}\n",
    "for c in coarse_dict:\n",
    "    distribution = {}\n",
    "    for s in coarse_dict[c]:\n",
    "        t_set = set()\n",
    "        for w_t in s.split('\\n'):\n",
    "            t = w_t.split('\\t')[1] \n",
    "            if t != 'O':\n",
    "                t_set.add(t.split('-')[0])\n",
    "        for t in t_set:\n",
    "            distribution[t] = distribution.get(t, 0) + 1\n",
    "    corse_distribution[c] = distribution\n",
    "with open('./continual/coarse/distribution.json', encoding='utf-8', mode='w') as f:\n",
    "    json.dump(corse_distribution, f)\n",
    "\n",
    "fine_distribution = {}\n",
    "for c in fine_dict:\n",
    "    distribution = {}\n",
    "    for s in fine_dict[c]:\n",
    "        t_set = set()\n",
    "        for w_t in s.split('\\n'):\n",
    "            t = w_t.split('\\t')[1] \n",
    "            #\\ .split('-')[0]\n",
    "            if t != 'O':\n",
    "                t_set.add(t)\n",
    "        for t in t_set:\n",
    "            distribution[t] = distribution.get(t, 0) + 1\n",
    "    fine_distribution[c] = distribution\n",
    "\n",
    "with open('./continual/fine/distribution.json', encoding='utf-8', mode='w') as f:\n",
    "    json.dump(fine_distribution, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "755eb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del washed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb464d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9eccd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_coarse_dict, no_fine_dict = {}, {}\n",
    "for coarse in coarse_classes:\n",
    "    sample_ids = coarse_sid_dict[coarse]\n",
    "    no_samples = []\n",
    "    for sample_id in sample_ids:\n",
    "        sample = coarse_sentences[sample_id]\n",
    "        wts = sample.split('\\n')\n",
    "        for i in range(len(wts)):\n",
    "            word_tag = wts[i].split('\\t')\n",
    "            if word_tag[1] != 'O' and word_tag[1] != coarse:\n",
    "                word_tag[1] = 'O'\n",
    "                wts[i] = '\\t'.join(word_tag)\n",
    "        no_samples.append('\\n'.join(wts))\n",
    "    no_coarse_dict[coarse] = no_samples\n",
    "for fine in fine_classes:\n",
    "    sample_ids = fine_sid_dict[fine]\n",
    "    no_samples = []\n",
    "    for sample_id in sample_ids:\n",
    "        sample = all_sentences[sample_id]\n",
    "        wts = sample.split('\\n')\n",
    "        for i in range(len(wts)):\n",
    "            word_tag = wts[i].split('\\t')\n",
    "            if word_tag[1] != 'O' and word_tag[1] != fine:\n",
    "                word_tag[1] = 'O'\n",
    "                wts[i] = '\\t'.join(word_tag)\n",
    "        no_samples.append('\\n'.join(wts))\n",
    "    no_fine_dict[fine] = no_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4683e03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building : train : 10297; valid: 1471; test : 2941; total : 14709; ratio : 0.7000475899109389\n",
      "product : train : 10580; valid: 1512; test : 3022; total : 15114; ratio : 0.7000132327643245\n",
      "art : train : 8874; valid: 1268; test : 2534; total : 12676; ratio : 0.7000631113916062\n",
      "location : train : 20868; valid: 2982; test : 5961; total : 29811; ratio : 0.7000100633994163\n",
      "organization : train : 17674; valid: 2525; test : 5049; total : 25248; ratio : 0.7000158428390367\n",
      "other : train : 14248; valid: 2036; test : 4069; total : 20353; ratio : 0.7000442195253771\n",
      "person : train : 15647; valid: 2236; test : 4469; total : 22352; ratio : 0.7000268432355047\n",
      "event : train : 9887; valid: 1413; test : 2824; total : 14124; ratio : 0.7000141602945341\n",
      "================================================\n",
      "person-scholar : train : 1447; valid: 207; test : 413; total : 2067; ratio : 0.7000483792936623\n",
      "location-bodiesofwater : train : 2011; valid: 288; test : 573; total : 2872; ratio : 0.700208913649025\n",
      "product-airplane : train : 1456; valid: 208; test : 415; total : 2079; ratio : 0.7003367003367004\n",
      "building-library : train : 894; valid: 128; test : 254; total : 1276; ratio : 0.700626959247649\n",
      "person-politician : train : 3092; valid: 442; test : 883; total : 4417; ratio : 0.7000226398007697\n",
      "person-athlete : train : 3129; valid: 447; test : 894; total : 4470; ratio : 0.7\n",
      "other-chemicalthing : train : 1482; valid: 212; test : 422; total : 2116; ratio : 0.7003780718336484\n",
      "product-other : train : 2211; valid: 316; test : 631; total : 3158; ratio : 0.7001266624445852\n",
      "other-biologything : train : 1874; valid: 268; test : 535; total : 2677; ratio : 0.7000373552484124\n",
      "organization-showorganization : train : 1367; valid: 196; test : 389; total : 1952; ratio : 0.7003073770491803\n",
      "art-film : train : 1222; valid: 175; test : 348; total : 1745; ratio : 0.7002865329512894\n",
      "organization-other : train : 4187; valid: 599; test : 1195; total : 5981; ratio : 0.700050158836315\n",
      "building-other : train : 3138; valid: 449; test : 895; total : 4482; ratio : 0.7001338688085676\n",
      "organization-politicalparty : train : 1830; valid: 262; test : 522; total : 2614; ratio : 0.7000765110941086\n",
      "event-election : train : 504; valid: 72; test : 143; total : 719; ratio : 0.7009735744089013\n",
      "building-hotel : train : 756; valid: 108; test : 215; total : 1079; ratio : 0.70064874884152\n",
      "location-other : train : 2492; valid: 356; test : 712; total : 3560; ratio : 0.7\n",
      "art-music : train : 1470; valid: 210; test : 419; total : 2099; ratio : 0.7003334921391139\n",
      "other-livingthing : train : 1349; valid: 193; test : 384; total : 1926; ratio : 0.7004153686396677\n",
      "product-game : train : 924; valid: 132; test : 263; total : 1319; ratio : 0.7005307050796058\n",
      "building-sportsfacility : train : 1106; valid: 158; test : 316; total : 1580; ratio : 0.7\n",
      "other-law : train : 1248; valid: 179; test : 355; total : 1782; ratio : 0.7003367003367004\n",
      "event-sportsevent : train : 2846; valid: 407; test : 812; total : 4065; ratio : 0.7001230012300123\n",
      "event-protest : train : 473; valid: 68; test : 134; total : 675; ratio : 0.7007407407407408\n",
      "building-restaurant : train : 539; valid: 77; test : 154; total : 770; ratio : 0.7\n",
      "art-painting : train : 150; valid: 22; test : 41; total : 213; ratio : 0.704225352112676\n",
      "other-language : train : 1389; valid: 199; test : 395; total : 1983; ratio : 0.7004538577912254\n",
      "location-road,railway,highway,transit : train : 2467; valid: 353; test : 703; total : 3523; ratio : 0.7002554640931025\n",
      "product-weapon : train : 1032; valid: 148; test : 294; total : 1474; ratio : 0.7001356852103121\n",
      "product-car : train : 1243; valid: 178; test : 354; total : 1775; ratio : 0.7002816901408451\n",
      "other-educationaldegree : train : 823; valid: 118; test : 234; total : 1175; ratio : 0.7004255319148937\n",
      "person-artist,author : train : 2221; valid: 318; test : 633; total : 3172; ratio : 0.7001891551071879\n",
      "person-other : train : 5897; valid: 843; test : 1683; total : 8423; ratio : 0.7001068502908703\n",
      "person-soldier : train : 1435; valid: 205; test : 409; total : 2049; ratio : 0.7003416300634456\n",
      "other-disease : train : 1322; valid: 189; test : 377; total : 1888; ratio : 0.7002118644067796\n",
      "other-astronomything : train : 1165; valid: 167; test : 331; total : 1663; ratio : 0.7005411906193626\n",
      "other-god : train : 873; valid: 125; test : 249; total : 1247; ratio : 0.7000801924619086\n",
      "person-director : train : 1156; valid: 166; test : 329; total : 1651; ratio : 0.7001817080557238\n",
      "product-software : train : 1339; valid: 192; test : 381; total : 1912; ratio : 0.7003138075313807\n",
      "other-currency : train : 1366; valid: 196; test : 389; total : 1951; ratio : 0.7001537672988212\n",
      "art-writtenart : train : 1571; valid: 225; test : 447; total : 2243; ratio : 0.700401248328132\n",
      "building-theater : train : 1075; valid: 154; test : 306; total : 1535; ratio : 0.7003257328990228\n",
      "organization-company : train : 3373; valid: 482; test : 963; total : 4818; ratio : 0.7000830220008302\n",
      "organization-sportsleague : train : 1895; valid: 271; test : 540; total : 2706; ratio : 0.7002956393200296\n",
      "organization-education : train : 2278; valid: 326; test : 649; total : 3253; ratio : 0.7002766676913618\n",
      "organization-government,governmentagency : train : 2225; valid: 318; test : 635; total : 3178; ratio : 0.7001258653241033\n",
      "event-other : train : 1504; valid: 215; test : 429; total : 2148; ratio : 0.7001862197392924\n",
      "art-broadcastprogram : train : 1221; valid: 175; test : 348; total : 1744; ratio : 0.7001146788990825\n",
      "location-park : train : 1059; valid: 152; test : 301; total : 1512; ratio : 0.7003968253968254\n",
      "event-attack,battle,war,militaryconflict : train : 1721; valid: 246; test : 491; total : 2458; ratio : 0.7001627339300244\n",
      "other-award : train : 1475; valid: 211; test : 420; total : 2106; ratio : 0.7003798670465338\n",
      "building-hospital : train : 866; valid: 124; test : 246; total : 1236; ratio : 0.7006472491909385\n",
      "location-GPE : train : 6912; valid: 988; test : 1973; total : 9873; ratio : 0.7000911577028259\n",
      "product-food : train : 731; valid: 105; test : 208; total : 1044; ratio : 0.7001915708812261\n",
      "organization-religion : train : 1382; valid: 198; test : 393; total : 1973; ratio : 0.7004561581348201\n",
      "location-mountain : train : 1301; valid: 186; test : 371; total : 1858; ratio : 0.7002152852529602\n",
      "art-other : train : 1070; valid: 153; test : 305; total : 1528; ratio : 0.7002617801047121\n",
      "organization-sportsteam : train : 1716; valid: 246; test : 489; total : 2451; ratio : 0.7001223990208079\n",
      "organization-media,newspaper : train : 1448; valid: 207; test : 413; total : 2068; ratio : 0.7001934235976789\n",
      "product-ship : train : 981; valid: 141; test : 279; total : 1401; ratio : 0.7002141327623126\n",
      "location-island : train : 1209; valid: 173; test : 345; total : 1727; ratio : 0.7000579038795599\n",
      "person-actor : train : 1122; valid: 161; test : 319; total : 1602; ratio : 0.700374531835206\n",
      "building-airport : train : 896; valid: 128; test : 255; total : 1279; ratio : 0.7005473025801408\n",
      "event-disaster : train : 614; valid: 88; test : 175; total : 877; ratio : 0.7001140250855188\n",
      "other-medical : train : 839; valid: 120; test : 239; total : 1198; ratio : 0.7003338898163606\n",
      "product-train : train : 695; valid: 100; test : 197; total : 992; ratio : 0.7006048387096774\n"
     ]
    }
   ],
   "source": [
    "no_coarse_train_samples, no_coarse_valid_samples, no_coarse_test_samples = {}, {}, {}\n",
    "no_coarse_train_indices, no_coarse_valid_indices, no_coarse_test_indices = {}, {}, {}\n",
    "no_fine_train_samples, no_fine_valid_samples, no_fine_test_samples = {}, {}, {}\n",
    "no_fine_train_indices, no_fine_valid_indices, no_fine_test_indices = {}, {}, {}\n",
    "\n",
    "for c in coarse_classes:\n",
    "    sample_ids = coarse_sid_dict[c]\n",
    "    train_sample_id_indices, valid_sample_id_indices = set(), set()\n",
    "    train_count, valid_count = 0, 0\n",
    "    while train_count < 0.7 * coarse_tag_count[c]:\n",
    "        sample_id_idx = random.choice(range(len(sample_ids)))\n",
    "        if sample_id_idx not in train_sample_id_indices:\n",
    "            train_sample_id_indices.add(sample_id_idx)\n",
    "            train_count += 1\n",
    "    while valid_count < 0.1 * coarse_tag_count[c]:\n",
    "        sample_id_idx = random.choice(range(len(sample_ids)))\n",
    "        if sample_id_idx not in train_sample_id_indices and sample_id_idx not in valid_sample_id_indices:\n",
    "            valid_sample_id_indices.add(sample_id_idx)\n",
    "            valid_count += 1\n",
    "    test_sample_id_indices = set(range(len(sample_ids))).difference(train_sample_id_indices.union(valid_sample_id_indices))\n",
    "    no_coarse_train_samples[c] = [no_coarse_dict[c][sample_id_idx] for sample_id_idx in train_sample_id_indices]\n",
    "    no_coarse_valid_samples[c] = [no_coarse_dict[c][sample_id_idx] for sample_id_idx in valid_sample_id_indices]\n",
    "    no_coarse_test_samples[c] = [no_coarse_dict[c][sample_id_idx] for sample_id_idx in test_sample_id_indices]\n",
    "    no_coarse_train_indices[c] = train_sample_id_indices\n",
    "    no_coarse_valid_indices[c] = valid_sample_id_indices\n",
    "    no_coarse_test_indices[c] = test_sample_id_indices\n",
    "for c in coarse_tag_count:\n",
    "    print(f'{c} : train : {len(no_coarse_train_samples[c])}; valid: {len(no_coarse_valid_samples[c])}; test : {len(no_coarse_test_samples[c])}; total : {coarse_tag_count[c]}; ratio : {len(no_coarse_train_samples[c]) / coarse_tag_count[c]}')\n",
    "\n",
    "    \n",
    "print('================================================')\n",
    "\n",
    "    \n",
    "for c in fine_classes:\n",
    "    sample_ids = fine_sid_dict[c]\n",
    "    train_sample_id_indices, valid_sample_id_indices = set(), set()\n",
    "    train_count, valid_count = 0, 0\n",
    "    while train_count < 0.7 * fine_tag_count[c]:\n",
    "        sample_id_idx = random.choice(range(len(sample_ids)))\n",
    "        if sample_id_idx not in train_sample_id_indices:\n",
    "            train_sample_id_indices.add(sample_id_idx)\n",
    "            train_count += 1\n",
    "    while valid_count < 0.1 * fine_tag_count[c]:\n",
    "        sample_id_idx = random.choice(range(len(sample_ids)))\n",
    "        if sample_id_idx not in train_sample_id_indices and sample_id_idx not in valid_sample_id_indices:\n",
    "            valid_sample_id_indices.add(sample_id_idx)\n",
    "            valid_count += 1\n",
    "    test_sample_id_indices = set(range(len(sample_ids))).difference(train_sample_id_indices.union(valid_sample_id_indices))\n",
    "    no_fine_train_samples[c] = [no_fine_dict[c][sample_id_idx] for sample_id_idx in train_sample_id_indices]\n",
    "    no_fine_valid_samples[c] = [no_fine_dict[c][sample_id_idx] for sample_id_idx in valid_sample_id_indices]\n",
    "    no_fine_test_samples[c] = [no_fine_dict[c][sample_id_idx] for sample_id_idx in test_sample_id_indices]\n",
    "    no_fine_train_indices[c] = train_sample_id_indices\n",
    "    no_fine_valid_indices[c] = valid_sample_id_indices\n",
    "    no_fine_test_indices[c] = test_sample_id_indices\n",
    "for c in fine_tag_count:\n",
    "    print(f'{c} : train : {len(no_fine_train_samples[c])}; valid: {len(no_fine_valid_samples[c])}; test : {len(no_fine_test_samples[c])}; total : {fine_tag_count[c]}; ratio : {len(no_fine_train_samples[c]) / fine_tag_count[c]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a05535b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building : train : 10297; total : 14709; ratio : 0.7000475899109389\n",
      "product : train : 10580; total : 15114; ratio : 0.7000132327643245\n",
      "art : train : 8874; total : 12676; ratio : 0.7000631113916062\n",
      "location : train : 20868; total : 29811; ratio : 0.7000100633994163\n",
      "organization : train : 17674; total : 25248; ratio : 0.7000158428390367\n",
      "other : train : 14248; total : 20353; ratio : 0.7000442195253771\n",
      "person : train : 15647; total : 22352; ratio : 0.7000268432355047\n",
      "event : train : 9887; total : 14124; ratio : 0.7000141602945341\n",
      "person-scholar : train : 1447; total : 2067; ratio : 0.7000483792936623\n",
      "location-bodiesofwater : train : 2011; total : 2872; ratio : 0.700208913649025\n",
      "product-airplane : train : 1456; total : 2079; ratio : 0.7003367003367004\n",
      "building-library : train : 894; total : 1276; ratio : 0.700626959247649\n",
      "person-politician : train : 3092; total : 4417; ratio : 0.7000226398007697\n",
      "person-athlete : train : 3129; total : 4470; ratio : 0.7\n",
      "other-chemicalthing : train : 1482; total : 2116; ratio : 0.7003780718336484\n",
      "product-other : train : 2211; total : 3158; ratio : 0.7001266624445852\n",
      "other-biologything : train : 1874; total : 2677; ratio : 0.7000373552484124\n",
      "organization-showorganization : train : 1367; total : 1952; ratio : 0.7003073770491803\n",
      "art-film : train : 1222; total : 1745; ratio : 0.7002865329512894\n",
      "organization-other : train : 4187; total : 5981; ratio : 0.700050158836315\n",
      "building-other : train : 3138; total : 4482; ratio : 0.7001338688085676\n",
      "organization-politicalparty : train : 1830; total : 2614; ratio : 0.7000765110941086\n",
      "event-election : train : 504; total : 719; ratio : 0.7009735744089013\n",
      "building-hotel : train : 756; total : 1079; ratio : 0.70064874884152\n",
      "location-other : train : 2492; total : 3560; ratio : 0.7\n",
      "art-music : train : 1470; total : 2099; ratio : 0.7003334921391139\n",
      "other-livingthing : train : 1349; total : 1926; ratio : 0.7004153686396677\n",
      "product-game : train : 924; total : 1319; ratio : 0.7005307050796058\n",
      "building-sportsfacility : train : 1106; total : 1580; ratio : 0.7\n",
      "other-law : train : 1248; total : 1782; ratio : 0.7003367003367004\n",
      "event-sportsevent : train : 2846; total : 4065; ratio : 0.7001230012300123\n",
      "event-protest : train : 473; total : 675; ratio : 0.7007407407407408\n",
      "building-restaurant : train : 539; total : 770; ratio : 0.7\n",
      "art-painting : train : 150; total : 213; ratio : 0.704225352112676\n",
      "other-language : train : 1389; total : 1983; ratio : 0.7004538577912254\n",
      "location-road,railway,highway,transit : train : 2467; total : 3523; ratio : 0.7002554640931025\n",
      "product-weapon : train : 1032; total : 1474; ratio : 0.7001356852103121\n",
      "product-car : train : 1243; total : 1775; ratio : 0.7002816901408451\n",
      "other-educationaldegree : train : 823; total : 1175; ratio : 0.7004255319148937\n",
      "person-artist,author : train : 2221; total : 3172; ratio : 0.7001891551071879\n",
      "person-other : train : 5897; total : 8423; ratio : 0.7001068502908703\n",
      "person-soldier : train : 1435; total : 2049; ratio : 0.7003416300634456\n",
      "other-disease : train : 1322; total : 1888; ratio : 0.7002118644067796\n",
      "other-astronomything : train : 1165; total : 1663; ratio : 0.7005411906193626\n",
      "other-god : train : 873; total : 1247; ratio : 0.7000801924619086\n",
      "person-director : train : 1156; total : 1651; ratio : 0.7001817080557238\n",
      "product-software : train : 1339; total : 1912; ratio : 0.7003138075313807\n",
      "other-currency : train : 1366; total : 1951; ratio : 0.7001537672988212\n",
      "art-writtenart : train : 1571; total : 2243; ratio : 0.700401248328132\n",
      "building-theater : train : 1075; total : 1535; ratio : 0.7003257328990228\n",
      "organization-company : train : 3373; total : 4818; ratio : 0.7000830220008302\n",
      "organization-sportsleague : train : 1895; total : 2706; ratio : 0.7002956393200296\n",
      "organization-education : train : 2278; total : 3253; ratio : 0.7002766676913618\n",
      "organization-government,governmentagency : train : 2225; total : 3178; ratio : 0.7001258653241033\n",
      "event-other : train : 1504; total : 2148; ratio : 0.7001862197392924\n",
      "art-broadcastprogram : train : 1221; total : 1744; ratio : 0.7001146788990825\n",
      "location-park : train : 1059; total : 1512; ratio : 0.7003968253968254\n",
      "event-attack,battle,war,militaryconflict : train : 1721; total : 2458; ratio : 0.7001627339300244\n",
      "other-award : train : 1475; total : 2106; ratio : 0.7003798670465338\n",
      "building-hospital : train : 866; total : 1236; ratio : 0.7006472491909385\n",
      "location-GPE : train : 6912; total : 9873; ratio : 0.7000911577028259\n",
      "product-food : train : 731; total : 1044; ratio : 0.7001915708812261\n",
      "organization-religion : train : 1382; total : 1973; ratio : 0.7004561581348201\n",
      "location-mountain : train : 1301; total : 1858; ratio : 0.7002152852529602\n",
      "art-other : train : 1070; total : 1528; ratio : 0.7002617801047121\n",
      "organization-sportsteam : train : 1716; total : 2451; ratio : 0.7001223990208079\n",
      "organization-media,newspaper : train : 1448; total : 2068; ratio : 0.7001934235976789\n",
      "product-ship : train : 981; total : 1401; ratio : 0.7002141327623126\n",
      "location-island : train : 1209; total : 1727; ratio : 0.7000579038795599\n",
      "person-actor : train : 1122; total : 1602; ratio : 0.700374531835206\n",
      "building-airport : train : 896; total : 1279; ratio : 0.7005473025801408\n",
      "event-disaster : train : 614; total : 877; ratio : 0.7001140250855188\n",
      "other-medical : train : 839; total : 1198; ratio : 0.7003338898163606\n",
      "product-train : train : 695; total : 992; ratio : 0.7006048387096774\n"
     ]
    }
   ],
   "source": [
    "coarse_train_samples, coarse_test_samples = {}, {}\n",
    "fine_train_samples, fine_test_samples = {}, {}\n",
    "for c in coarse_classes:\n",
    "    train_samples = [coarse_dict[c][i] for i in no_coarse_train_indices[c]]\n",
    "    coarse_train_samples[c] = train_samples\n",
    "for c in coarse_tag_count:\n",
    "    print(f'{c} : train : {len(coarse_train_samples[c])}; total : {coarse_tag_count[c]}; ratio : {len(coarse_train_samples[c]) / coarse_tag_count[c]}')\n",
    "# remained_samples = set()\n",
    "for c in fine_classes:\n",
    "    train_samples = [fine_dict[c][i] for i in no_fine_train_indices[c]]\n",
    "    fine_train_samples[c] = train_samples\n",
    "#     remained_samples = remained_samples.union(set([fine_dict[c][i] for i in no_fine_test_indices[c]]))\n",
    "for c in fine_tag_count:\n",
    "    print(f'{c} : train : {len(fine_train_samples[c])}; total : {fine_tag_count[c]}; ratio : {len(fine_train_samples[c]) / fine_tag_count[c]}')\n",
    "\n",
    "# for c in fine_tag_count:\n",
    "#     train_samples = fine_train_samples[c]\n",
    "#     train_dist = {}\n",
    "#     for train_sample in train_samples:\n",
    "#         tags = set(wt .split('\\t')[1] for wt in train_sample.split('\\n'))\n",
    "#         tags.remove('O')\n",
    "#         for tag in tags:\n",
    "#             train_dist[tag] = train_dist.get(tag, 0) + 1\n",
    "#     test_samples, test_tag_count = set(), {}\n",
    "#     for train_tag in train_dist:\n",
    "#         visited = set()\n",
    "#         while test_tag_count.get(train_tag, 0) < (0.25 * train_dist[train_tag] if train_dist[train_tag] > 4 else 1):\n",
    "#             test_sample = random.choice(list(remained_samples))\n",
    "#             visited.add(test_sample)\n",
    "#             if visited == remained_samples:\n",
    "#                 print('No satisfied sample. Exit search.')\n",
    "#                 break\n",
    "#             if test_sample not in test_samples and test_sample not in train_samples:\n",
    "#                 satisfied = True\n",
    "#                 tags = set([wt.split('\\t')[1] for wt in test_sample.split('\\n')])\n",
    "#                 tags.remove('O')\n",
    "#                 if tags.issubset(train_dist.keys()):\n",
    "#                     for t in tags:\n",
    "#                         if test_tag_count.get(t, 0) + 1 > (0.25 * train_dist[t] if train_dist[t] > 4 else 1):\n",
    "#                             satisfied = False\n",
    "#                             break\n",
    "#                 else:\n",
    "#                     satisfied = False\n",
    "#                 if satisfied:\n",
    "#                     test_samples.add(test_sample)\n",
    "#                     remained_samples.remove(test_sample)\n",
    "#                     visited.remove(test_sample)\n",
    "#                     test_tag_count[train_tag] = test_tag_count.get(train_tag, 0) + 1\n",
    "#                     for t in tags:\n",
    "#                         if t != 'O' and t != train_tag:\n",
    "#                             test_tag_count[t] = test_tag_count.get(t, 0) + 1\n",
    "#     fine_test_samples[c] = test_samples\n",
    "#     print(f'{c} test samples found!')\n",
    "# for c in tag_count:\n",
    "#     print(f'{c} : test : {len(fine_test_samples[c])}; total : {fine_tag_count[c]}; ratio : {len(fine_test_samples[c]) / fine_tag_count[c]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7deb2f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(parent_dir, samples_dict, mode):\n",
    "    for fname in samples_dict:\n",
    "        path = os.path.join(parent_dir, fname)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        with open(os.path.join(path, mode+'.txt'), 'w', encoding='utf-8') as f:\n",
    "            f.writelines('\\n\\n'.join(samples_dict[fname]))\n",
    "save_file('./continual/coarse/non-overlapping', no_coarse_train_samples, mode='train')\n",
    "save_file('./continual/coarse/non-overlapping', no_coarse_valid_samples, mode='dev')\n",
    "save_file('./continual/coarse/non-overlapping', no_coarse_test_samples, mode='test')\n",
    "save_file('./continual/fine/non-overlapping', no_fine_train_samples, mode='train')\n",
    "save_file('./continual/fine/non-overlapping', no_fine_valid_samples, mode='dev')\n",
    "save_file('./continual/fine/non-overlapping', no_fine_test_samples, mode='test')\n",
    "save_file('./continual/fine/overlapping', fine_train_samples, mode='train')\n",
    "save_file('./continual/coarse/overlapping', coarse_train_samples, mode='train')\n",
    "\n",
    "# save_file('./continual/fine/overlapping', fine_test_samples, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b654cec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e797c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
